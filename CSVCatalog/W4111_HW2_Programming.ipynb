{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style  type=\"text/css\"> \n",
    "</style>\n",
    "\n",
    "<b><center>\n",
    "<span style=\"font-size: 24pt; line-height: 1.2\">\n",
    "COMS W4111-002 (Fall 2021)<br>Introduction to Databases\n",
    "</span>\n",
    "</center></b>\n",
    "</span><br>\n",
    "<p>\n",
    "<i><center>\n",
    "<span style=\"font-size: 20pt; line-height: 1.2\">\n",
    "Homework 2: Programming Implement a Simple Database Engine<br>15 Points\n",
    "</span>\n",
    "</center></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This assignment is due October 22, 11:59 pm EDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ Please replace the information below with your last name, first name and UNI.<br><br>\n",
    "\n",
    "\n",
    "\n",
    "<i>\n",
    "<span style=\"font-size: 20pt; line-height: 1.2\"; >\n",
    "Yi_Yang, yy3089\n",
    "</span>\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission\n",
    "1. File > Print Preview > Save as PDF...\n",
    "2. Upload .pdf and .ipynb to GradeScope\n",
    "\n",
    "**This assignment is due October 22, 11:59 pm EDT**\n",
    "\n",
    "\n",
    "### Collaboration\n",
    "- You may use any information you get in TA or Prof. Ferguson's office hours, from lectures or from recitations.\n",
    "- You may use information that you find on the web.\n",
    "- You are NOT allowed to collaborate with other students outside of office hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Written & SQL\n",
    "\n",
    "### Written \n",
    "Please keep your answers brief."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Codd's Fourth Rule states that: The data base description is represented at the logical level in the same way as ordinary data, so that authorized users can apply the same relational language to its interrogation as they apply to the regular data. In two sentences please explain this rule and why it is so important.\n",
    "\n",
    "Metadata stored in the data dictionary should obey all the characteristics of a database and it should have correct up to date data. We should be able to access these metadata by using same query language that we use to access the database.\n",
    "\n",
    "https://www.tutorialcup.com/dbms/codds-rule.htm#Active_Online_Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Give 3 examples of what would be stored in a database catalog.\n",
    "\n",
    "base tables, views, indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What is the SQL database catalog called?\n",
    "\n",
    "INFORMATION_SCHEMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What is the overall goal of indices in SQL?\n",
    "\n",
    "An index contains keys built from one or more columns in the table or view. These keys are stored in a structure (B-tree) that enables SQL Server to find the row or rows associated with the key values quickly and efficiently. Clustered indexes sort and store the data rows in the table or view based on their key values.\n",
    "\n",
    "https://docs.microsoft.com/en-us/sql/relational-databases/indexes/clustered-and-nonclustered-indexes-described?view=sql-server-ver15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What are the differences between a primary key and a unique index?\n",
    "\n",
    "Primary key will not accept NULL values whereas Unique key can accept NULL values. A table can have only primary key whereas there can be multiple unique key on a table. A Clustered index is automatically created when a primary key is defined whereas Unique key generates the non-clustered index.\n",
    "\n",
    "https://www.geeksforgeeks.org/difference-between-primary-key-and-unique-key/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Which SELECT statement is more efficient? Why? \n",
    "\n",
    "- <code> SELECT playerID,birthState,nameLast,nameFirst FROM people \n",
    "where birthCountry = 'USA' and nameFirst = 'John' and playerID in (select playerID from collegeplaying where schoolID = 'Fordham'); </code>\n",
    "\n",
    "\n",
    "- <code> SELECT playerID,birthState,nameLast,nameFirst FROM people NATURAL JOIN collegeplaying \n",
    "where birthCountry = 'USA' and nameFirst = 'John' and schoolID = 'Fordham' group by playerID,birthState,nameLast,nameFirst; </code>\n",
    "\n",
    "HINT: SQL uses a query optimizer so you can't just run both of these and see which one performs faster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. The create.sql file provided in the zip folder makes a schema and some tables that mimics metadata tables. Note there is the sytax \"ON DELETE CASCADE\" after the foreign key creation. What does this mean? Why do we want to specify CASCADE for the metadata tables? What does \"ON DELETE RESTRICT\" mean and when would we generally want to use this? \n",
    "\n",
    "CASCADE means that the child data is either deleted or updated when the parent data is deleted or updated. ON DELETE CASCADE means that if a record in the parent table is deleted, then the corresponding records in the child table will automatically be deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql mysql+pymysql://root:dbuserdbuser@localhost/lahmansbaseballdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Initials\n",
    "\n",
    "- Find the ```initials, firstName, lastName```, for every player from the people table.\n",
    "\n",
    "- You need to return 10 rows.\n",
    "\n",
    "- Sort by the nameFirst, nameLast ascending. \n",
    "\n",
    "- Note: Even for those players with two last names, just return the first letter of their first last name\n",
    "\n",
    "<u>Answer:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "select concat(ifnull(substr(nameFirst,1,1),'_'), ifnull(substr(nameLast,1,1),'_')) as initials, \n",
    "ifnull(nameFirst, '____') as firstName, \n",
    "nameLast as lastName \n",
    "from lahmansbaseballdb.people \n",
    "order by firstName, lastName \n",
    "limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1a): Games Per Player using GROUP BY\n",
    "\n",
    "- Find the ```yearID, lgID, games_per_player```, for every year and league from the appearances table.\n",
    "\n",
    "- Use a function to round down the games_per_player\n",
    "\n",
    "- You need to return 10 rows.\n",
    "\n",
    "- You must use `group by` in this query.\n",
    "\n",
    "<u>Answer:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT yearID, lgID, round(sum(G_all)/count(distinct playerID)) as games_per_player FROM lahmansbaseballdb.appearances \n",
    "group by yearID, lgID\n",
    "limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: CSVCatalog Tests\n",
    "\n",
    "Once you have tested everything successfuly in python, execute your tests one more time in jupyter notebook to show the expected output. You will need to restart your kernel after saving your python files so that jupyter will use the most recent version of your work. \n",
    "\n",
    "You may need to drop tables before executing your tests one last time so you don't run into integrity errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unit_test_catalog as cat # This notebook should be in the same directory as your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running save core definition\n",
      "Q =  insert into csvtables values(%s, %s)\n",
      "Running load core definition\n",
      "Q =  select * from csvtables where table_name = 'test_table'\n",
      "Running load columns\n",
      "Q =  select * from csvcolumns where table_name = 'test_table'\n",
      "Running load indexes\n",
      "Q =  select * from csvindexes where table_name = 'test_table' group by index_name, table_name, type, column_name, index_order order by index_order\n",
      "Table =  {\n",
      "  \"table_name\": \"test_table\",\n",
      "  \"file_name\": \"./Appearances.csv\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat.create_table_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q =  DELETE FROM csvtables WHERE table_name = 'test_table'\n",
      "Table 'test_table' was dropped\n",
      "Drop test_table\n"
     ]
    }
   ],
   "source": [
    "cat.drop_table_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running save core definition\n",
      "Q =  insert into csvtables values(%s, %s)\n",
      "Running load core definition\n",
      "Q =  select * from csvtables where table_name = 'test_table'\n",
      "Running load columns\n",
      "Q =  select * from csvcolumns where table_name = 'test_table'\n",
      "Running load indexes\n",
      "Q =  select * from csvindexes where table_name = 'test_table' group by index_name, table_name, type, column_name, index_order order by index_order\n",
      "Table =  {\n",
      "  \"table_name\": \"test_table\",\n",
      "  \"file_name\": \"./Appearances.csv\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat.create_table_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running load core definition\n",
      "Q =  select * from csvtables where table_name = 'test_table'\n",
      "Running load columns\n",
      "Q =  select * from csvcolumns where table_name = 'test_table'\n",
      "Running load indexes\n",
      "Q =  select * from csvindexes where table_name = 'test_table' group by index_name, table_name, type, column_name, index_order order by index_order\n",
      "Q =  insert into csvcolumns values(%s, %s, %s, %s)\n"
     ]
    }
   ],
   "source": [
    "cat.add_column_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "issue!!\n",
      "You must have a column name!!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cat.column_name_failure_test()  # This will throw an error\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue!\n",
      "That column type is not accepted. Please try again.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cat.column_type_failure_test()  # This will throw an error\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "issue!\n",
      "The not_null column must be either True or False! Please try again.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cat.column_not_null_failure_test()  # This will throw an error\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running load core definition\n",
      "Q =  select * from csvtables where table_name = 'test_table'\n",
      "Running load columns\n",
      "Q =  select * from csvcolumns where table_name = 'test_table'\n",
      "Running load indexes\n",
      "Q =  select * from csvindexes where table_name = 'test_table' group by index_name, table_name, type, column_name, index_order order by index_order\n",
      "Q =  insert into csvindexes (table_name, column_name, type, index_name, index_order)  values(%s, %s, %s, %s, %s)\n"
     ]
    }
   ],
   "source": [
    "cat.add_index_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running load core definition\n",
      "Q =  select * from csvtables where table_name = 'test_table'\n",
      "Running load columns\n",
      "Q =  select * from csvcolumns where table_name = 'test_table'\n",
      "Running load indexes\n",
      "Q =  select * from csvindexes where table_name = 'test_table' group by index_name, table_name, type, column_name, index_order order by index_order\n",
      "Q =  delete from csvcolumns where table_name = 'test_table' and column_name = 'test_column'\n",
      "Column 'test_column' has been dropped!\n"
     ]
    }
   ],
   "source": [
    "cat.col_drop_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running load core definition\n",
      "Q =  select * from csvtables where table_name = 'test_table'\n",
      "Running load columns\n",
      "Q =  select * from csvcolumns where table_name = 'test_table'\n",
      "Running load indexes\n",
      "Q =  select * from csvindexes where table_name = 'test_table' group by index_name, table_name, type, column_name, index_order order by index_order\n",
      "Running drop index\n",
      "Q =  delete from csvindexes where table_name = 'test_table' and index_name = 'test_index'\n"
     ]
    }
   ],
   "source": [
    "cat.index_drop_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running load core definition\n",
      "Q =  select * from csvtables where table_name = 'test_table'\n",
      "Running load columns\n",
      "Q =  select * from csvcolumns where table_name = 'test_table'\n",
      "Running load indexes\n",
      "Q =  select * from csvindexes where table_name = 'test_table' group by index_name, table_name, type, column_name, index_order order by index_order\n",
      "DESCRIBE test_table = \n",
      " {\n",
      "  \"table_name\": \"test_table\",\n",
      "  \"file_name\": \"./Appearances.csv\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat.describe_table_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q =  DELETE FROM csvtables WHERE table_name = 'test_table'\n",
      "Table 'test_table' was dropped\n",
      "Drop test_table\n"
     ]
    }
   ],
   "source": [
    "cat.drop_table_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: CSVTable Tests\n",
    "\n",
    "In the event that the data sent is too large, jupyter notebook will throw a warning and not print any output. This will happen when you try to retrieve an entire table. Don't worry about getting the output if this happens. \n",
    "\n",
    "Additonally, the table formatting will get messed up if the columns makes the output too wide. In your tests make sure you project fields so that your outputs are legible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unit_test_csv_table as tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the tables if you already made them when testing\n",
    "tab.drop_tables_for_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.create_lahman_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.update_people_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.update_appearances_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.update_batting_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.add_index_definitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.test_load_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.test_get_col_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.add_other_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should throw an error\n",
    "# Make sure it works properly when you run it in pycharm though!\n",
    "tab.load_test() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might throw an error depending on table size\n",
    "# Make sure it works properly when you run it in pycharm though!\n",
    "tab.dumb_join_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.get_access_path_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.sub_where_template_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.test_find_by_template_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.smart_join_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the time it takes to do the dumb join and the smart join below\n",
    "%time #This is a timer that will track how long it takes to execute your cell. \n",
    "\n",
    "# Times will vary based on how long it takes to query your AWS Server, but you should see a notable improvement using smart_join()\n",
    "\n",
    "#----Your Code Here----\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75d693246883545d612a5aac312e8d6da903cb98802ff81b7acc8d951aee9eda"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('dbstudy': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
